[{"categories":["papers"],"content":"2022年最新发表的NeuS变种：Geo-NeuS","date":"0001-01-01","objectID":"/geo-neus/","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":["papers"],"content":"公式推导 用有符号距离函数表示空间点p到物体表面的距离，sdf(p)等于0 $$\\partial \\Omega={\\boldsymbol{p} \\mid s d f(\\boldsymbol{p})=0}$$ 使用两个神经网络估计SDF和颜色场 $$s \\hat{d} f(\\boldsymbol{p})=F_{\\Theta}(\\boldsymbol{p})$$ $$\\hat{c}(\\boldsymbol{o}, \\boldsymbol{v}, t)=G_{\\Phi}(\\boldsymbol{o}, \\boldsymbol{v}, t)$$ 表示颜色场： $$ C=\\hat{C}=\\sum_{i=1}^n w\\left(t_i\\right) \\hat{c}\\left(t_i\\right) $$ 由于需要专注于表面的重建，所以将公式改写为 $$ \\begin{aligned} C \u0026 =\\sum_{i=1}^{j-1} w\\left(t_i\\right) \\hat{c}\\left(t_i\\right)+w\\left(t_j\\right) \\hat{c}\\left(\\hat{t^}\\right)+w\\left(t_j\\right)\\left(\\hat{c}\\left(t_j\\right)-\\hat{c}\\left(\\hat{t^}\\right)\\right)+\\sum_{i=j+1}^n w\\left(t_i\\right) \\hat{c}\\left(t_i\\right) \\ \u0026 =w\\left(t_j\\right) \\hat{c}\\left(\\hat{t^}\\right)+\\varepsilon_{\\text {sample }}+\\sum_{\\substack{i=1 \\ i \\neq j}}^n w\\left(t_i\\right) \\hat{c}\\left(t_i\\right) \\ \u0026 =w\\left(t_j\\right) \\hat{c}\\left(\\hat{t^}\\right)+\\varepsilon_{\\text {sample }}+\\varepsilon_{\\text {weight }}, \\end{aligned} $$ 公式推导\r最后得到偏差的表达式： $$ \\Delta c=\\hat{c}\\left(\\hat{t}^\\right)-c\\left(t^\\right)=\\frac{\\left(1-w\\left(t_j\\right)\\right) c\\left(t^\\right)-\\varepsilon_{\\text {sample }}-\\varepsilon_{\\text {weight }}}{w\\left(t_j\\right)} $$ $$ \\delta c=\\frac{\\Delta c}{c\\left(t^\\right)}=\\frac{1}{w\\left(t_j\\right)}-1-\\frac{\\varepsilon_{\\text {sample }}+\\varepsilon_{\\text {weight }}}{w\\left(t_j\\right) c\\left(t^*\\right)} . $$ 网络的架构图，结合了三种loss，五个通道 架构图\r闭塞处理，这里没有看懂在干什么 Occlusion handling. Because we focus on opaque objects, some parts of objects are invisible from view of a certain camera position. Therefore, there are only some of the sparse points visible for each view. For an image $I_i$ with camera position $\\boldsymbol{o}_i$, the visible points $\\boldsymbol{P}_i$ are consistent with feature points $\\boldsymbol{X}_i$ of $I_i$ $$ \\boldsymbol{X}_i=\\boldsymbol{K}_i\\left[\\boldsymbol{R}_i \\mid \\boldsymbol{t}_i\\right] \\boldsymbol{P}_i $$ where $\\boldsymbol{K}_i$ is the internal calibration matrix, $\\boldsymbol{R}_i$ is the rotation matrix and $\\boldsymbol{t}_i$ is the translation vector for image $I_i$. The coordinates of $\\boldsymbol{X}_i$ and $\\boldsymbol{P}_i$ are all homogeneous coordinates. The scale index before $\\boldsymbol{X}_i$ is omitted for simplicity. According to feature points of each image, we get visible points for each view and use them to supervise the SDF network while rendering image from the corresponding view. SDF loss View-aware SDF loss. While rendering image $I_i$ from view $V_i$, we use the SDF network to estimate SDF values for the visible points $\\boldsymbol{P}i$ of $V_i$. Based on the approximation that the SDF values of sparse points are zeroes, we propose the view-aware SDF loss: $$ \\mathcal{L}{S D F}=\\sum_{\\boldsymbol{p}_j \\in \\boldsymbol{P}_i} \\frac{1}{N_i}\\left|s \\hat{d} f\\left(\\boldsymbol{p}_j\\right)-s d f\\left(\\boldsymbol{p}j\\right)\\right|=\\sum{\\boldsymbol{p}_j \\in \\boldsymbol{P}_i} \\frac{1}{N_i}\\left|s \\hat{d} f\\left(\\boldsymbol{p}_j\\right)\\right|, $$ where $N_i$ is the number of points in $\\boldsymbol{P}_i$ and $|\\cdot|$ denotes the $L_1$ distance. It is worth noting that the loss we use to supervise the SDF network varies according to the view being rendered. In this way, the introduced SDF loss is consistent with the process of color rendering. 值得注意的是，我们用来监督SDF网络的损失根据所呈现的视图而有所不同。这样，引入的SDF损失与显色渲染的过程是一致的。 这个loss应该向0收敛吗？是的 这里提到了他的模型使用了几何先验，是使用了什么作为先验？ 表达隐式平面，通过正负距离确定表面点。使用线性插值的方法求交点集。 Occlusion-aware implicit surface capture. We use the implicit representation of the surface, and extract surface with the zero-level set of the implicit function. So the question is: Where is our implicit surface? According to Formula (3), the estimated surface is: $$ \\hat{\\partial \\Omega}={\\boldsymbol{p} \\mid s \\hat{d} f(\\boldsymbol{p})=0} . $$ We aim to optimize $\\hat{\\partial \\Omega}$ with geometry-consistent constraints among different views. Because the number of points on the surface is infinite, we need to sample points from $\\hat{\\partial \\Omega}$ in practice. To maintain consistency with the process of color rendering usin","date":"0001-01-01","objectID":"/geo-neus/:1:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":["papers"],"content":"代码复现 conda activate报错 CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'. 解决方案： source activate # 执行后命令行出现base标识 conda activate ... conda activate pytorch 报错 Could not find conda environment: pytorch You can list all discoverable environments with `conda info --envs`. conda install pytorch Executing transaction: failed ERROR conda.core.link:_execute(502): An error occurred while installing package 'conda-forge::certifi-2022.9.24-pyhd8ed1ab_0'. FileNotFoundError(2, \"No such file or directory: '/home/hanqi/.conda/envs/geoneus/bin/python3.7'\") Attempting to roll back. Rolling back transaction: done FileNotFoundError(2, \"No such file or directory: '/home/hanqi/.conda/envs/geoneus/bin/python3.7'\") 默认的安装路径是错的，我把forge卸载了，之后可以正常安装 anaconda search -t conda fvcore anaconda show ... 不知道为什么，anaconda3文件夹设置的是read only，如果要进行更新操作必须切换root用户 sudo s # 切换root用户 exit # 退出回到原来的用户 程序运行一段时间被kill了，定位发现是在这句话的时候 self.images_gray = torch.from_numpy(self.images_gray_np.astype(np.float32)).cuda() .cuda()是把数据储存到显卡里，可能是数据量太大了，我删除了一些照片，还剩十几张 训练过程中报错缺失npy文件 FileNotFoundError: [Errno 2] No such file or directory: 'pikachu_aruco/sfm_pts/points.npy' 查找后发现是作者没有给出这个文件的计算方法，只是说要modify 这个文件 运行指令需要两个，一个是数据文件夹，一个是保存的路径，直接运行报下面的错误 FileNotFoundError: [Errno 2] No such file or directory: 'pikachu_aruco/sparse/cameras.txt' 这个文件作者没有提供，也没有解释文件的内容是什么 fields.py 分成四个class，SDF network, Rendering netwrk, SingleVariance network 和 NeRF ","date":"0001-01-01","objectID":"/geo-neus/:2:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":null,"content":"关于我","date":"2023-01-05","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":" 👋 Hi! I am Hanqi Jiang from Beijing Jiaotong University 👀 My Research Directions: Computer vision, deep learning, 3D reconstruction 📫 Contact me at: 20722010@bjtu.edu.cn or jhqyyds@gmail.com ","date":"2023-01-05","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Scientific research experience 2022.1 - 2022.3 CV algorithm intern at Baidu Online Network Technology (Beijing) Co., LTD., Xiaodu Cloud Platform Department, DuerOS algorithm team. 2022.4 - 2022.8 Algorithm engineer at China Telecom Co., Ltd. Beijing Research Institute China Telecom. 2022.4 - 2022.10 Algorithm engineer at Intelligent Computer Research Center, Institute of Computing Technology, Chinese Academy of Sciences. 2022.10 - 2023.4 Algorithm intern at Tsinghua University, autonomous driving lab. ","date":"2023-01-05","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Published paper Yuan, X., Jiang, H., \u0026 Zeng, L. (2023). Study on the process of preparing C4 olefin by catalytic coupling of ethanol. In Energy Revolution and Chemical Research (pp. 595-602). CRC Press. Available at: click here Yuan, X., Jiang, H., \u0026 Huang, L. (2022, August). DRL-Based Quantitative Algorithms for Gold and Bitcoin Portfolio Decisions. In 2022 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA) (pp. 878-881). IEEE. Available at: click here Liu, Z., Jiang, H., \u0026 Wang, T. (2022, October). Design and implementation of a quantitative investment system based on deep learning and data mining. In 2022 IEEE 2nd International Conference on Data Science and Computer Application (ICDSCA) (pp. 162-166). IEEE. Available at: click here ","date":"2023-01-05","objectID":"/about/:2:0","tags":null,"title":"关于我","uri":"/about/"}]