[{"categories":["Course notes"],"content":"111","date":"2023-01-26","objectID":"/computer-network-review/","tags":["Computer network"],"title":"计网复习","uri":"/computer-network-review/"},{"categories":["Course notes"],"content":"Week 1 updated in 2023/1/27 ","date":"2023-01-26","objectID":"/computer-network-review/:1:0","tags":["Computer network"],"title":"计网复习","uri":"/computer-network-review/"},{"categories":["Course notes"],"content":"1. What is a network Any set of interconnected nodes through horizontal and or vertical lines. 通过平行或者垂直的线，连接起来的节点的集合 有什么样的网络，（除了计网之外的例子）: Telephone network carrying voice traffic, Cable network to disseminate video signals ","date":"2023-01-26","objectID":"/computer-network-review/:1:1","tags":["Computer network"],"title":"计网复习","uri":"/computer-network-review/"},{"categories":["Course notes"],"content":"2. 什么是计算机网络？computer network A computer network is a group of computers that use a set of common communication protocols over digital interconnections for the purpose of sharing resources. 计算机网络是一组计算机，它们通过数字互连使用一套共同的通信协议，以达到共享资源的目的。 Set of connected autonomous computers (having programmable hardware) 是一系列自治的，互联的，有可编程硬件的计算机的集合 2.1 计网的功能，为什么需要计网 Resource Sharing, Information Sharing, Ease in Communication 资源共享，信息共享，方便沟通 2.2 计网的类型 2.2.1 直接连接 点对点point to point 就是两台计算机一条线连起来，常用于远程的广域网链接 多重连接multiple access 就是多台计算机连接一条总线,通常用于局域网链接 2.2.2 非直接连接 （用交换机）电路交换，包交换 ","date":"2023-01-26","objectID":"/computer-network-review/:1:2","tags":["Computer network"],"title":"计网复习","uri":"/computer-network-review/"},{"categories":["Course notes"],"content":"3. 什么是互联网？internet The internet is a computer network that interconnects billions of computing devices using communication links and packet switches. 互联网是一个计算机网络，利用通信链路和分组交换机将数十亿的计算设备（称为主机或终端系统）互联起来。 互联网是最为熟知的计算机网络。 有两种不同的描述internet的方法，一种是由组成部件去描述internet，另一种是从提供服务的角度描述internet 3.1 a “nuts and bolts” view，具体来看什么是internet The basic hardware and software components that make up the Internet. nuts and bolts view\r3.1.1 Devices 主机（hosts） = 终端（end systems） running network apps at internet’s eges 3.1.2 Packet switches 路由器（routers） 交换机（switches） 3.1.3 Communication links 光纤、铜线、无线电、卫星fiber copper radio satellite 传输速率：带宽 3.1.4 Networks 1. 设备、路由器、链接的集合：由一个组织管理collection of devices, routers, links: managed by an organization ","date":"2023-01-26","objectID":"/computer-network-review/:1:3","tags":["Computer network"],"title":"计网复习","uri":"/computer-network-review/"},{"categories":["papers"],"content":"2022年最新发表的NeuS变种：Geo-NeuS","date":"2023-01-15","objectID":"/geo-neus-renderer/","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"get_psnr def get_psnr(img1, img2, normalize_rgb=False): if normalize_rgb: # [-1,1] --\u003e [0,1] img1 = (img1 + 1.) / 2. img2 = (img2 + 1. ) / 2. mse = torch.mean((img1 - img2) ** 2) psnr = -10. * torch.log(mse) / torch.log(torch.Tensor([10.]).cuda()) return psnr 这个函数计算两张图像img1和img2的峰值信噪比（PSNR）。如果normalize_rgb标志设置为True，函数将通过将范围从[-1,1]转换为[0,1]来标准化图像。然后，函数通过计算两张图像的像素值之差的平方平均值来计算两幅图像之间的均方误差（MSE）。然后使用MSE和最大可能像素值（对于8位图像为255）的log base 10计算PSNR。返回最终的PSNR值。 ","date":"2023-01-15","objectID":"/geo-neus-renderer/:1:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"extract_fields def extract_fields(bound_min, bound_max, resolution, query_func): N = 64 X = torch.linspace(bound_min[0], bound_max[0], resolution).split(N) Y = torch.linspace(bound_min[1], bound_max[1], resolution).split(N) Z = torch.linspace(bound_min[2], bound_max[2], resolution).split(N) u = np.zeros([resolution, resolution, resolution], dtype=np.float32) with torch.no_grad(): for xi, xs in enumerate(X): for yi, ys in enumerate(Y): for zi, zs in enumerate(Z): xx, yy, zz = torch.meshgrid(xs, ys, zs) pts = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1) val = query_func(pts).reshape(len(xs), len(ys), len(zs)).detach().cpu().numpy() u[xi * N: xi * N + len(xs), yi * N: yi * N + len(ys), zi * N: zi * N + len(zs)] = val return u 这个函数通过在由边界框坐标和分辨率定义的网格上的点上调用查询函数来提取字段。该函数首先将网格分割成大小为N = 64的块，然后使用torch.linspace()函数生成一组线性间隔值，用于x，y和z维。然后，函数使用嵌套for循环遍历网格的块，对于每个块，它使用该块中的点调用查询函数，并将结果存储在u数组中。 这个函数使用numpy库创建数组，Pytorch创建点网格并将它们分块处理。 ","date":"2023-01-15","objectID":"/geo-neus-renderer/:2:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"extract_geometry def extract_geometry(bound_min, bound_max, resolution, threshold, query_func): print('threshold: {}'.format(threshold)) u = extract_fields(bound_min, bound_max, resolution, query_func) vertices, triangles = mcubes.marching_cubes(u, threshold) b_max_np = bound_max.detach().cpu().numpy() b_min_np = bound_min.detach().cpu().numpy() vertices = vertices / (resolution - 1.0) * (b_max_np - b_min_np)[None, :] + b_min_np[None, :] return vertices, triangles 这个函数通过使用Marching Cubes算法来从3D场中提取几何体。它接受四个参数：bound_min和bound_max是3D空间的下限和上限，resolution是每个维度上的点数，threshold是Marching Cubes算法用来确定场中哪些点被认为是几何体的一部分的值，query_func是返回场在一组点上的值的函数。 该函数首先调用extract_fields()函数获取一个3D场，然后将场和阈值值传递给mcubes库中的marching_cubes()函数，该函数返回提取的几何体的顶点和三角形。然后，缩放并偏移顶点以匹配由bound_min和bound_max指定的边界框。 该函数使用Pytorch处理数据，使用mcubes库提取几何体，并使用Pytorch将张量转换为numpy数组。 ","date":"2023-01-15","objectID":"/geo-neus-renderer/:3:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"sample_pdf def sample_pdf(bins, weights, n_samples, det=False): # This implementation is from NeRF # Get pdf weights = weights + 1e-5 # prevent nans pdf = weights / torch.sum(weights, -1, keepdim=True) cdf = torch.cumsum(pdf, -1) cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], -1) # Take uniform samples if det: u = torch.linspace(0. + 0.5 / n_samples, 1. - 0.5 / n_samples, steps=n_samples) u = u.expand(list(cdf.shape[:-1]) + [n_samples]) else: u = torch.rand(list(cdf.shape[:-1]) + [n_samples]) # Invert CDF u = u.contiguous() inds = torch.searchsorted(cdf, u, right=True) below = torch.max(torch.zeros_like(inds - 1), inds - 1) above = torch.min((cdf.shape[-1] - 1) * torch.ones_like(inds), inds) inds_g = torch.stack([below, above], -1) # (batch, N_samples, 2) matched_shape = [inds_g.shape[0], inds_g.shape[1], cdf.shape[-1]] cdf_g = torch.gather(cdf.unsqueeze(1).expand(matched_shape), 2, inds_g) bins_g = torch.gather(bins.unsqueeze(1).expand(matched_shape), 2, inds_g) denom = (cdf_g[..., 1] - cdf_g[..., 0]) denom = torch.where(denom \u003c 1e-5, torch.ones_like(denom), denom) t = (u - cdf_g[..., 0]) / denom samples = bins_g[..., 0] + t * (bins_g[..., 1] - bins_g[..., 0]) return samples 这个函数用于采样一维的概率密度函数（PDF）。 函数的输入参数有： bins：一个 tensor，表示每个 bin 的中心点。 weights：一个 tensor，表示每个 bin 的权重。 n_samples：一个整数，表示采样样本数。 det：一个布尔值，表示是否为确定性采样（即采样点是等间隔分布的）。 这个函数首先使用权重对每个 bin 计算出概率密度函数（PDF），然后使用累积分布函数（CDF）对每个 bin 计算出累积概率，之后根据输入参数 det 来决定采样点是等间隔分布的还是随机分布的。最后，函数通过反演 CDF 来获取采样点在哪两个 bin 之间，然后使用线性插值计算出采样点的值。最后返回计算出来的样本。 ","date":"2023-01-15","objectID":"/geo-neus-renderer/:4:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"class GeoNeuSRenderer ","date":"2023-01-15","objectID":"/geo-neus-renderer/:5:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"render_core_outside def render_core_outside(self, rays_o, rays_d, z_vals, sample_dist, nerf, background_rgb=None): \"\"\" Render background \"\"\" batch_size, n_samples = z_vals.shape # Section length dists = z_vals[..., 1:] - z_vals[..., :-1] dists = torch.cat([dists, torch.Tensor([sample_dist]).expand(dists[..., :1].shape)], -1) mid_z_vals = z_vals + dists * 0.5 # Section midpoints pts = rays_o[:, None, :] + rays_d[:, None, :] * mid_z_vals[..., :, None] # batch_size, n_samples, 3 dis_to_center = torch.linalg.norm(pts, ord=2, dim=-1, keepdim=True).clip(1.0, 1e10) pts = torch.cat([pts / dis_to_center, 1.0 / dis_to_center], dim=-1) # batch_size, n_samples, 4 dirs = rays_d[:, None, :].expand(batch_size, n_samples, 3) pts = pts.reshape(-1, 3 + int(self.n_outside \u003e 0)) dirs = dirs.reshape(-1, 3) density, sampled_color = nerf(pts, dirs) alpha = 1.0 - torch.exp(-F.softplus(density.reshape(batch_size, n_samples)) * dists) alpha = alpha.reshape(batch_size, n_samples) weights = alpha * torch.cumprod(torch.cat([torch.ones([batch_size, 1]), 1. - alpha + 1e-7], -1), -1)[:, :-1] sampled_color = sampled_color.reshape(batch_size, n_samples, 3) color = (weights[:, :, None] * sampled_color).sum(dim=1) if background_rgb is not None: color = color + background_rgb * (1.0 - weights.sum(dim=-1, keepdim=True)) return { 'color': color, 'sampled_color': sampled_color, 'alpha': alpha, 'weights': weights, } 这是一个用于渲染三维图像的函数。它输入的参数有： rays_o：一个 tensor，表示射线的起点。 rays_d：一个 tensor，表示射线的方向。 z_vals：一个 tensor，表示射线经过的每个层的深度值。 sample_dist：一个浮点数，表示采样距离。 nerf：一个函数，用于计算密度和颜色。 background_rgb：一个三元组，表示背景颜色。 这个函数首先计算出射线经过的每个层之间的距离，然后计算出这些层的中心点。之后使用 nerf 函数计算出密度和颜色。之后计算出透明度并计算出权重。最后，函数通过将采样颜色与权重相乘并求和得到最终颜色。如果背景颜色不为空，函数将最终颜色加上背景颜色。最后返回一个字典，包含最终颜色，采样颜色，透明度和权重。 ","date":"2023-01-15","objectID":"/geo-neus-renderer/:5:1","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"up_sample def up_sample(self, rays_o, rays_d, z_vals, sdf, n_importance, inv_s): \"\"\" Up sampling give a fixed inv_s \"\"\" batch_size, n_samples = z_vals.shape pts = rays_o[:, None, :] + rays_d[:, None, :] * z_vals[..., :, None] # n_rays, n_samples, 3 radius = torch.linalg.norm(pts, ord=2, dim=-1, keepdim=False) inside_sphere = (radius[:, :-1] \u003c 1.0) | (radius[:, 1:] \u003c 1.0) sdf = sdf.reshape(batch_size, n_samples) prev_sdf, next_sdf = sdf[:, :-1], sdf[:, 1:] prev_z_vals, next_z_vals = z_vals[:, :-1], z_vals[:, 1:] mid_sdf = (prev_sdf + next_sdf) * 0.5 cos_val = (next_sdf - prev_sdf) / (next_z_vals - prev_z_vals + 1e-5) # ---------------------------------------------------------------------------------------------------------- # Use min value of [ cos, prev_cos ] # Though it makes the sampling (not rendering) a little bit biased, this strategy can make the sampling more # robust when meeting situations like below: # # SDF # ^ # |\\ -----x----... # | \\ / # | x x # |---\\----/-------------\u003e 0 level # | \\ / # | \\/ # | # ---------------------------------------------------------------------------------------------------------- prev_cos_val = torch.cat([torch.zeros([batch_size, 1]), cos_val[:, :-1]], dim=-1) cos_val = torch.stack([prev_cos_val, cos_val], dim=-1) cos_val, _ = torch.min(cos_val, dim=-1, keepdim=False) cos_val = cos_val.clip(-1e3, 0.0) * inside_sphere dist = (next_z_vals - prev_z_vals) prev_esti_sdf = mid_sdf - cos_val * dist * 0.5 next_esti_sdf = mid_sdf + cos_val * dist * 0.5 prev_cdf = torch.sigmoid(prev_esti_sdf * inv_s) next_cdf = torch.sigmoid(next_esti_sdf * inv_s) alpha = (prev_cdf - next_cdf + 1e-5) / (prev_cdf + 1e-5) weights = alpha * torch.cumprod( torch.cat([torch.ones([batch_size, 1]), 1. - alpha + 1e-7], -1), -1)[:, :-1] z_samples = sample_pdf(z_vals, weights, n_importance, det=True).detach() return z_samples 这是一个用于重采样三维图像的函数。它输入的参数有 rays_o：一个 tensor，表示射线的起点。 rays_d：一个 tensor，表示射线的方向。 z_vals：一个 tensor，表示射线经过的每个层的深度值。 sdf：一个 tensor，表示每个层的距离场。 n_importance：一个整数，表示重采样的样本数。 inv_s：一个浮点数，表示缩放因子。 这个函数首先计算出射线经过的每个层的点坐标。然后计算出当前层与下一层中点的距离场值，这个值被用来估计下一层距离场的值。之后计算出对于每个层之间的权重并使用 sample_pdf 函数进行重采样，最后返回重采样后的深度值。 ","date":"2023-01-15","objectID":"/geo-neus-renderer/:5:2","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["papers"],"content":"cat_z_vals def cat_z_vals(self, rays_o, rays_d, z_vals, new_z_vals, sdf, last=False): batch_size, n_samples = z_vals.shape _, n_importance = new_z_vals.shape pts = rays_o[:, None, :] + rays_d[:, None, :] * new_z_vals[..., :, None] z_vals = torch.cat([z_vals, new_z_vals], dim=-1) z_vals, index = torch.sort(z_vals, dim=-1) if not last: new_sdf = self.sdf_network.sdf(pts.reshape(-1, 3)).reshape(batch_size, n_importance) sdf = torch.cat([sdf, new_sdf], dim=-1) xx = torch.arange(batch_size)[:, None].expand(batch_size, n_samples + n_importance).reshape(-1) index = index.reshape(-1) sdf = sdf[(xx, index)].reshape(batch_size, n_samples + n_importance) return z_vals, sdf 这是一个用于将新的深度值和距离场值添加到已有深度值和距离场值上的函数。它输入的参数有： rays_o：一个 tensor，表示射线的起点。 rays_d：一个 tensor，表示射线的方向。 z_vals：一个 tensor，表示已有的射线经过的每个层的深度值。 new_z_vals：一个 tensor，表示新的射线经过的每个层的深度值。 sdf：一个 tensor，表示已有的每个层的距离场。 last：一个布尔值，表示是否是最后一次添加。 这个函数首先将新的深度值和已有的深度值连接在一起，然后对深度值进行排序。如果 last 为 False，函数使用网络计算新的距离场值并将其与已有的距离场值连接在一起。最后，函数返回深度值和距离场值。 ","date":"2023-01-15","objectID":"/geo-neus-renderer/:5:3","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus中renderer代码的具体解读","uri":"/geo-neus-renderer/"},{"categories":["Course notes"],"content":"复习","date":"2023-01-14","objectID":"/operating-system-review/","tags":["Operating systems"],"title":"操作系统考点总结（按章节）","uri":"/operating-system-review/"},{"categories":["Course notes"],"content":"\rtip\r这是我总结的操作系统的考点，但内容并不完善，可以参考这篇笔记，里面有更详细的我关于知识点的记录\r","date":"2023-01-14","objectID":"/operating-system-review/:0:0","tags":["Operating systems"],"title":"操作系统考点总结（按章节）","uri":"/operating-system-review/"},{"categories":["Course notes"],"content":"Chapter 1 updated in 2023.1.13 1. Monolithic OS（单一型）的优缺点？（单一型是os类型之一，用户和系统放在一起） 优：(1) efficient; (2) better performance 缺：(1) Difficult to impose security; (2) difficult to maintain 2. Layered OS： 优：security 缺：hard to manage; weak performance 3. Micro-Kernel OS (微内核os)： 优：security；extensible 缺：inefficient 4. Library OS (库操作系统)： 优：libraries provide additional security and personality 缺：less consistency(缺乏稳定性) ","date":"2023-01-14","objectID":"/operating-system-review/:1:0","tags":["Operating systems"],"title":"操作系统考点总结（按章节）","uri":"/operating-system-review/"},{"categories":["Course notes"],"content":"Chapter 2 updated in 2023.1.13 1. One or more threads in a single process Thread: smallest sequence of instructions managed independently by scheduler. Scheduler: method for how work is assigned to resources to complete work 2. Concurrency \u0026 parallelism (并发和并行)的区别？ Concurrency: processes are underway simultaneously, different processes execute one by one. Parallelism: Multiple (n \u003e 1) processes executing simultaneously. 对于并发，在同一时间点任务不同时execute；对于并行，在同一时间点任务一定同时execute，并发和并行都是针对process而言的 Processes are always concurrent, but not always parallel 3. 怎样创建一个线程：通过implement Runnable 类，里面有一个public void run( ) 方法 Define class R which implements Runnable Create your objects Make an instance of class R Make a thread instance by passing instance of class R to the constructor of class Thread Class start() method of the thread instance This causes java to immediately execute R.run() as a new thread 替代方法还可以创建一个类继承Thread类，理论上和实现Runnable是一样的 public class MessagePrinter extends Thread { String message; public MessagePrinter(String m) { message = m; } public void run() { for(int i = 0; i \u003c 1000; i++) System.out.println(message); } } 4. Processor（处理器）, program（程序）, process（进程） 三者区别？ Processor: Hardware device that executes machine instructions Program: Instruction sequence; Stored on disk 指令集；存储在硬盘上 Process：Program in execution on a processor; store in primary memory Program may be executed by multiple processes at the same time Process can run multiple programs. (多个thread) 5. When do we not have to worry about concurrency? no shared data or communication read only data 6. When should we worry about concurrency? （并发带来坏的影响） Threads access a shared resource without synchronization One or more threads modify the shared resource ","date":"2023-01-14","objectID":"/operating-system-review/:2:0","tags":["Operating systems"],"title":"操作系统考点总结（按章节）","uri":"/operating-system-review/"},{"categories":["Course notes"],"content":"Chapter 3 updated in 2023.1.13 1. Moore’s Law: Number of transistors in dense(密集) integrated circuits doubles every 2 years. 2. 为什么要用并行？（两个原因） Moore’s Law(硬件): Number of transistors in dense(密集) integrated circuits doubles every 2 years. Amdahl’s Law(软件)：Speed up is limited by the serial（程序串行） part of the program 3. Definition of race condition An error (e.g. a lost update) that occurs due to multiple processes ‘racing’ in an uncontrolled manner through a section of non-atomic code 4. 什么是临界区（critical section）? Code section that accesses a shared resource. 5. What is Mutual exclusion? Only one thread can run within the critical section at any given time 6. 建立临界区的4种方法？ Lock: 设置两个状态held/not held，held表示有线程在critical section acquire代表需要lock，release代表不需要lock acuqire( ) and release( )\rlock在java中通过synchronized语句实现，synchronized可以应用于任何的代码块 public void synchronized update (int a) { balance=balance+a; } Monitors Semaphores Message 7. Atomic A property of a sequentially-executed section of code A context switch can’t happen (by definition) while an atomic section of code is being executed 8. Lock acquire( ) only blocks threads attempting to acquire the same lock. Must use same lock for all critical sections accessing the same data. 9. Three steps of context-switching sequence De-schedule currently-running thread Scheduler selects ‘best’ ready thread to run next Resume newly-selected thread ","date":"2023-01-14","objectID":"/operating-system-review/:3:0","tags":["Operating systems"],"title":"操作系统考点总结（按章节）","uri":"/operating-system-review/"},{"categories":["Course notes"],"content":"Chapter 4 updated in 2023.1.16 1. 信号量（改错）： typedef struct _sem { int val; /* semaphore value*/ Queue queue; / oper: put, get*/ } Sem void P(Sem s) { /* wait() procedure */ s-\u003eval = s-\u003eval - 1; if (s-\u003eval \u003c 0) { put(s-\u003equeue, getpid()); /* queue of PIDs */ sleep(getpid()); } } void V(Sem s) { /* signal() procedure */ s-\u003eval = s-\u003eval + 1; if (s-\u003eval \u003e= 0){ wakeup(get(s-\u003equeue));} } P等同于wait，V等同于signal sleep是通过把这个线程放到waiting queue中来block这个线程 wakeup是唤醒waiting queue中的线程，并放到running queue中 2. P，V操作如何在java和C下实现的？ Java: wait() \u0026 notify() C: acquire() \u0026 release() Unix: sleep() \u0026 wakeup() Distributed system分布式系统（Message Passing）: send() \u0026 receive() 3. 虚假唤醒（Spurious wakeup）是考试中一道大题 public class Semaphore { private int count = 0; public Semaphore(int init_val){ count = init_val; } public synchronized void P() { count = count - 1; if (count \u003c 0) wait(); } public synchronized void V() { count = count + 1; notifyAll(); } } 什么时候会引起虚假唤醒？ Answer: Does not recheck the condition，把P中的if改为while 4. 编程题： put() get()操作 public class BoxDimension{ private int dim = 0; private Semaphore sem = 1; public void put(int d) { dim = d; sem.signal(); } public int get() { sem.wait(); return dim; } } BoxDimension d = new BoxDimension(); 5. Java中的semaphore public class Semaphore { private int count = 0; public Semaphore(int init_val) { count = init_val; // Should check it’s \u003e= 0 } public synchronized void P() { count = count - 1; while (count \u003c 0) wait(); // why not ‘if’? } public synchronized void V() { count = count + 1; /* if there is one, wake a waiter; */ notifyAll(); /* why not use ‘notify()’? */ } } P中要使用while来判断是否要wait，因为如果条件满足要一直wait V中要使用notifyAll()，而不是notify()，因为notify()会导致deadlock ","date":"2023-01-14","objectID":"/operating-system-review/:4:0","tags":["Operating systems"],"title":"操作系统考点总结（按章节）","uri":"/operating-system-review/"},{"categories":["Course notes"],"content":"Chapter 5 ","date":"2023-01-14","objectID":"/operating-system-review/:5:0","tags":["Operating systems"],"title":"操作系统考点总结（按章节）","uri":"/operating-system-review/"},{"categories":["papers"],"content":"论文笔记","date":"2023-01-12","objectID":"/paper-depth-learning/","tags":["Deep learning","3D reconstruction"],"title":"Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video","uri":"/paper-depth-learning/"},{"categories":["papers"],"content":"Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video 根据摘要来看，文章主要提出了一种深度网络能够得出深度图 所以文章中的loss很有可能是主要对深度网络的表现做优化 code：点击跳转 ","date":"2023-01-12","objectID":"/paper-depth-learning/:0:0","tags":["Deep learning","3D reconstruction"],"title":"Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video","uri":"/paper-depth-learning/"},{"categories":["papers"],"content":"论文笔记 取连续两帧，通过深度网络转换成深度图，通过pose net得到相机位姿，将二者输入损失函数中 网络架构图\r这里需要看一下这个连续帧我们可不可以换成两个视角的照片 ","date":"2023-01-12","objectID":"/paper-depth-learning/:1:0","tags":["Deep learning","3D reconstruction"],"title":"Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video","uri":"/paper-depth-learning/"},{"categories":["papers"],"content":"photometric loss and geometry loss photometric loss\r光度一致性损失，这里没有看明白是如何把Ia投影到Ib，到底是否用到深度信息了，后面在代码部分探讨。 geometry consistency loss\r深度一致性损失比较好理解，就是直接通过深度图计算深度difference，作为深度一致性损失。 结合代码 根据上面的损失函数描述，定位到文件loss_functions.py class SSIM(nn.Module): \"\"\"Layer to compute the SSIM loss between a pair of images \"\"\" def __init__(self): super(SSIM, self).__init__() self.mu_x_pool = nn.AvgPool2d(3, 1) self.mu_y_pool = nn.AvgPool2d(3, 1) self.sig_x_pool = nn.AvgPool2d(3, 1) self.sig_y_pool = nn.AvgPool2d(3, 1) self.sig_xy_pool = nn.AvgPool2d(3, 1) self.refl = nn.ReflectionPad2d(1) self.C1 = 0.01 ** 2 self.C2 = 0.03 ** 2 def forward(self, x, y): x = self.refl(x) y = self.refl(y) mu_x = self.mu_x_pool(x) mu_y = self.mu_y_pool(y) sigma_x = self.sig_x_pool(x ** 2) - mu_x ** 2 sigma_y = self.sig_y_pool(y ** 2) - mu_y ** 2 sigma_xy = self.sig_xy_pool(x * y) - mu_x * mu_y SSIM_n = (2 * mu_x * mu_y + self.C1) * (2 * sigma_xy + self.C2) SSIM_d = (mu_x ** 2 + mu_y ** 2 + self.C1) * (sigma_x + sigma_y + self.C2) return torch.clamp((1 - SSIM_n / SSIM_d) / 2, 0, 1) compute_ssim_loss = SSIM().to(device) 利用torch求出SSIM loss，主要是减小两张不同图片造成的误差 def compute_pairwise_loss(tgt_img, ref_img, tgt_depth, ref_depth, pose, intrinsic, with_ssim, with_mask, with_auto_mask, padding_mode): ref_img_warped, valid_mask, projected_depth, computed_depth = inverse_warp2(ref_img, tgt_depth, ref_depth, pose, intrinsic, padding_mode) diff_img = (tgt_img - ref_img_warped).abs().clamp(0, 1) diff_depth = ((computed_depth - projected_depth).abs() / (computed_depth + projected_depth)).clamp(0, 1) if with_auto_mask == True: auto_mask = (diff_img.mean(dim=1, keepdim=True) \u003c (tgt_img - ref_img).abs().mean(dim=1, keepdim=True)).float() * valid_mask valid_mask = auto_mask if with_ssim == True: ssim_map = compute_ssim_loss(tgt_img, ref_img_warped) diff_img = (0.15 * diff_img + 0.85 * ssim_map) if with_mask == True: weight_mask = (1 - diff_depth) diff_img = diff_img * weight_mask # compute all loss reconstruction_loss = mean_on_mask(diff_img, valid_mask) geometry_consistency_loss = mean_on_mask(diff_depth, valid_mask) return reconstruction_loss, geometry_consistency_loss 求光度一致和几何一致损失 根据代码计算 diff_img和diff_depth的过程发现计算img是直接对图片作差，计算depth是对深度值作差 需要具体看一下tgt_img和ref_img是在哪里定义的，看这个compute在哪里被引用 ","date":"2023-01-12","objectID":"/paper-depth-learning/:1:1","tags":["Deep learning","3D reconstruction"],"title":"Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video","uri":"/paper-depth-learning/"},{"categories":["papers"],"content":"smoothness loss smoothness loss\r结合代码 def compute_smooth_loss(tgt_depth, tgt_img, ref_depths, ref_imgs): def get_smooth_loss(disp, img): \"\"\"Computes the smoothness loss for a disparity image The color image is used for edge-aware smoothness \"\"\" # normalize mean_disp = disp.mean(2, True).mean(3, True) norm_disp = disp / (mean_disp + 1e-7) disp = norm_disp grad_disp_x = torch.abs(disp[:, :, :, :-1] - disp[:, :, :, 1:]) grad_disp_y = torch.abs(disp[:, :, :-1, :] - disp[:, :, 1:, :]) grad_img_x = torch.mean(torch.abs(img[:, :, :, :-1] - img[:, :, :, 1:]), 1, keepdim=True) grad_img_y = torch.mean(torch.abs(img[:, :, :-1, :] - img[:, :, 1:, :]), 1, keepdim=True) grad_disp_x *= torch.exp(-grad_img_x) grad_disp_y *= torch.exp(-grad_img_y) return grad_disp_x.mean() + grad_disp_y.mean() loss = get_smooth_loss(tgt_depth[0], tgt_img) for ref_depth, ref_img in zip(ref_depths, ref_imgs): loss += get_smooth_loss(ref_depth[0], ref_img) return loss 这个损失函数输入两个target和两个reference ","date":"2023-01-12","objectID":"/paper-depth-learning/:1:2","tags":["Deep learning","3D reconstruction"],"title":"Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video","uri":"/paper-depth-learning/"},{"categories":["papers"],"content":"warp过程 定位到 ","date":"2023-01-12","objectID":"/paper-depth-learning/:1:3","tags":["Deep learning","3D reconstruction"],"title":"Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video","uri":"/paper-depth-learning/"},{"categories":["python"],"content":"python转换视频照片","date":"2023-01-09","objectID":"/convert/","tags":["python"],"title":"Python实现将视频转换为照片","uri":"/convert/"},{"categories":["python"],"content":"使用python将视频转换为照片 \"\"\" 将视频转换为图片，可以为多个文件夹下的图片。 注：在程序使用前需先配置好main中的地址 视频路径：video_path_list = [path1, path2, ...](路径数量可以为[1,n]，每个路径下的视频数也可为[1,m]) paht1 path2 .... |------video1.avi |-----video1.avi |------vidoe2.avi |-----... |------.... 图片存储路径：image_save_dir = save_path(存储方式则将按以下方式） save_path | -------path1_name |----video1 |----jpg1.jpg |----jpg2,jpg |----video2 ... |-------path2_name ... \"\"\" import cv2 import os from pathlib import Path VID_FORMATS = ('.mov', '.avi', '.mp4', '.mpg', '.mpeg', '.m4v', '.wmv', '.mkv', '.mp3') def videos2images(root_video_path, root_save_dir): for video_dir_path in root_video_path: # 1.检测读取文件路径是否正确 path_video = Path(video_dir_path) if path_video.is_dir(): print(video_dir_path + '\\t ok') videos = os.listdir(video_dir_path) else: print('\\033[31mLine36 error: \\033[31m' + video_dir_path + 'is not exist!') return # 2. 生成存储文件夹 save_name_dir = Path(path_video.name) save_name_dir = os.path.join(root_save_dir, save_name_dir) if not os.path.exists(save_name_dir): os.makedirs(save_name_dir) file_count = 0 for video in videos: # 判断是否为视频文件,如果不是视频文件则跳过并进行说明 if Path(video).suffix in VID_FORMATS: file_count += 1 # 视频文件数+1 save_jpg_dir = os.path.join(save_name_dir, Path(video).stem) if not os.path.exists(save_jpg_dir): os.makedirs(save_jpg_dir) each_video_path = os.path.join(path_video, video) save_dir = save_jpg_dir else: print('\\033[33mLine56 warning: \\033[33m' + os.path.basename(video) + ' is not a video file, so skip.') continue # 3. 开始转换。打印正在处理文件的序号和他的文件名，并开始转换 print('\\033[38m' + str(file_count) + ':' + Path(video).stem + '\\033[38m') cap = cv2.VideoCapture(each_video_path) flag = cap.isOpened() if not flag: print(\"\\033[31mLine 65 error\\033[31m: open\" + each_video_path + \"error!\") frame_count = 0 # 给每一帧标号 while True: frame_count += 1 flag, frame = cap.read() if not flag: # 如果已经读取到最后一帧则退出 break if os.path.exists( save_dir + str(frame_count) + '.jpg'): # 在源视频不变的情况下，如果已经创建，则跳过 break cv2.imwrite(save_dir + '\\\\' + str(frame_count) + '.jpg', frame) cap.release() print('\\033[38m' + Path(video).stem + ' save to ' + save_dir + 'finished. \\033[38m') # 表示一个视频片段已经转换完成 if __name__ == '__main__': # 需要转换的视频路径列表，直达视频文件(自定义修改） video_path_list = [r'video', r'video2'] # 预期存储在的主文件夹，即'result'文件夹下 image_save_dir = r'result2' path_save = Path(image_save_dir) if not path_save.exists(): path_save.mkdir() # 进行转换 videos2images(video_path_list, image_save_dir) ","date":"2023-01-09","objectID":"/convert/:0:0","tags":["python"],"title":"Python实现将视频转换为照片","uri":"/convert/"},{"categories":["网站使用笔记"],"content":"这篇文章展示了基本的 Markdown 语法和格式.","date":"2023-01-08","objectID":"/basic-markdown-syntax/","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"这篇文章提供了可以在 Hugo 的文章中使用的基本 Markdown 语法示例. 注意\r这篇文章借鉴了一篇很棒的来自 Grav 的文章. 如果你想了解 Loveit 主题的扩展 Markdown 语法, 请阅读扩展 Markdown 语法页面. 事实上, 编写 Web 内容很麻烦. WYSIWYG所见即所得 编辑器帮助减轻了这一任务. 但通常会导致代码太糟, 或更糟糕的是, 网页也会很丑. 没有通常伴随的所有复杂和丑陋的问题, Markdown 是一种更好的生成 HTML 内容的方式. 一些主要好处是: Markdown 简单易学, 几乎没有多余的字符, 因此编写内容也更快. 用 Markdown 书写时出错的机会更少. 可以产生有效的 XHTML 输出. 将内容和视觉显示保持分开, 这样就不会打乱网站的外观. 可以在你喜欢的任何文本编辑器或 Markdown 应用程序中编写内容. Markdown 使用起来很有趣! John Gruber, Markdown 的作者如是说: Markdown 格式的首要设计目标是更具可读性. 最初的想法是 Markdown 格式的文档应当以纯文本形式发布, 而不会看起来像被标签或格式说明所标记. 虽然 Markdown 的语法受到几种现有的文本到 HTML 转换工具的影响, 但 Markdown 语法的最大灵感来源是纯文本电子邮件的格式. – John Gruber 话不多说, 我们来回顾一下 Markdown 的主要语法以及生成的 HTML 样式! 技巧\r 将此页保存为书签，以备将来参考!\r","date":"2023-01-08","objectID":"/basic-markdown-syntax/:0:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"1 标题 从 h2 到 h6 的标题在每个级别上都加上一个 ＃: ## h2 标题 ### h3 标题 #### h4 标题 ##### h5 标题 ###### h6 标题 输出的 HTML 看起来像这样: \u003ch2\u003eh2 标题\u003c/h2\u003e \u003ch3\u003eh3 标题\u003c/h3\u003e \u003ch4\u003eh4 标题\u003c/h4\u003e \u003ch5\u003eh5 标题\u003c/h5\u003e \u003ch6\u003eh6 标题\u003c/h6\u003e 标题 ID\r要添加自定义标题 ID, 请在与标题相同的行中将自定义 ID 放在花括号中: ### 一个很棒的标题 {#custom-id} 输出的 HTML 看起来像这样: \u003ch3 id=\"custom-id\"\u003e一个很棒的标题\u003c/h3\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:1:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"2 注释 注释是和 HTML 兼容的： \u003c!-- 这是一段注释 --\u003e 不能看到以下的注释: ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:2:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"3 水平线 HTML 中的 \u003chr\u003e 标签是用来在段落元素之间创建一个 “专题间隔” 的. 使用 Markdown, 你可以用以下方式创建一个 \u003chr\u003e 标签: ___: 三个连续的下划线 ---: 三个连续的破折号 ***: 三个连续的星号 呈现的输出效果如下: ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:3:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"4 段落 按照纯文本的方式书写段落, 纯文本在呈现的 HTML 中将用 \u003cp\u003e/\u003c/p\u003e 标签包裹. 如下段落: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. 输出的 HTML 看起来像这样: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e 可以使用一个空白行进行换行. ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:4:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"5 内联 HTML 元素 如果你需要某个 HTML 标签 (带有一个类), 则可以简单地像这样使用: Markdown 格式的段落. \u003cdiv class=\"class\"\u003e 这是 \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Markdown 格式的段落. ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:5:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"6 强调 ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:6:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"加粗 用于强调带有较粗字体的文本片段. 以下文本片段会被 渲染为粗体. **渲染为粗体** __渲染为粗体__ 输出的 HTML 看起来像这样: \u003cstrong\u003e渲染为粗体\u003c/strong\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:6:1","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"斜体 用于强调带有斜体的文本片段. 以下文本片段被 渲染为斜体. *渲染为斜体* _渲染为斜体_ 输出的 HTML 看起来像这样: \u003cem\u003e渲染为斜体\u003c/em\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:6:2","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"删除线 按照 GFMGitHub flavored Markdown 你可以使用删除线. ~~这段文本带有删除线.~~ 呈现的输出效果如下: 这段文本带有删除线. 输出的 HTML 看起来像这样: \u003cdel\u003e这段文本带有删除线.\u003c/del\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:6:3","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"组合 加粗, 斜体, 和删除线可以 组合使用. ***加粗和斜体*** ~~**删除线和加粗**~~ ~~*删除线和斜体*~~ ~~***加粗, 斜体和删除线***~~ 呈现的输出效果如下: 加粗和斜体 删除线和加粗 删除线和斜体 加粗, 斜体和删除线 输出的 HTML 看起来像这样: \u003cem\u003e\u003cstrong\u003e加粗和斜体\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003e删除线和加粗\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e删除线和斜体\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003e加粗, 斜体和删除线\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:6:4","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"7 引用 用于在文档中引用其他来源的内容块. 在要引用的任何文本之前添加 \u003e: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 呈现的输出效果如下: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 输出的 HTML 看起来像这样: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e 引用也可以嵌套: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. 呈现的输出效果如下: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:7:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"8 列表 ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:8:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"无序列表 一系列项的列表, 其中项的顺序没有明显关系. 你可以使用以下任何符号来表示无序列表中的项: * 一项内容 - 一项内容 + 一项内容 例如: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:8:1","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"有序列表 一系列项的列表, 其中项的顺序确实很重要. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e 技巧\r如果你对每一项使用 1., Markdown 将自动为每一项编号. 例如: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:8:2","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"任务列表 任务列表使你可以创建带有复选框的列表. 要创建任务列表, 请在任务列表项之前添加破折号 (-) 和带有空格的方括号 ([ ]). 要选择一个复选框，请在方括号之间添加 x ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media 呈现的输出效果如下: Write the press release Update the website Contact the media ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:8:3","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"9 代码 ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:9:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"行内代码 用 ` 包装行内代码段. 在这个例子中, `\u003csection\u003e\u003c/section\u003e` 会被包裹成 **代码**. 呈现的输出效果如下: 在这个例子中, \u003csection\u003e\u003c/section\u003e 会被包裹成 代码. 输出的 HTML 看起来像这样: \u003cp\u003e 在这个例子中, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e 会被包裹成 \u003cstrong\u003e代码\u003c/strong\u003e. \u003c/p\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:9:1","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"缩进代码 将几行代码缩进至少四个空格，例如: // Some comments line 1 of code line 2 of code line 3 of code 呈现的输出效果如下: // Some comments\rline 1 of code\rline 2 of code\rline 3 of code\r输出的 HTML 看起来像这样: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:9:2","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"围栏代码块 使用 “围栏” ``` 来生成一段带有语言属性的代码块. ```markdown Sample text here... ``` 输出的 HTML 看起来像这样: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:9:3","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"语法高亮 GFMGitHub Flavored Markdown 也支持语法高亮. 要激活它，只需在第一个代码 “围栏” 之后直接添加你要使用的语言的文件扩展名, ```js, 语法高亮显示将自动应用于渲染的 HTML 中. 例如, 在以下 JavaScript 代码中应用语法高亮: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` 呈现的输出效果如下: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; 注意\rHugo 文档中的 语法高亮页面 介绍了有关语法高亮的更多信息, 包括语法高亮的 shortcode.\r","date":"2023-01-08","objectID":"/basic-markdown-syntax/:9:4","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"10 表格 通过在每个单元格之间添加竖线作为分隔线, 并在标题下添加一行破折号 (也由竖线分隔) 来创建表格. 注意, 竖线不需要垂直对齐. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. 输出的 HTML 看起来像这样: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e 文本右对齐或居中对齐\r在任何标题下方的破折号右侧添加冒号将使该列的文本右对齐. 在任何标题下方的破折号两边添加冒号将使该列的对齐文本居中. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:10:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"11 链接 ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:11:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"基本链接 \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) 呈现的输出效果如下 (将鼠标悬停在链接上，没有提示): https://assemble.io contact@revolunet.com Assemble 输出的 HTML 看起来像这样: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:11:1","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"添加一个标题 [Upstage](https://github.com/upstage/ \"Visit Upstage!\") 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage 输出的 HTML 看起来像这样: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:11:2","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"定位标记 定位标记使你可以跳至同一页面上的指定锚点. 例如, 每个章节: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) 将跳转到这些部分: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. 注意\r定位标记的位置几乎是任意的. 因为它们并不引人注目, 所以它们通常被放在同一行了.\r","date":"2023-01-08","objectID":"/basic-markdown-syntax/:11:3","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"12 脚注 脚注使你可以添加注释和参考, 而不会使文档正文混乱. 当你创建脚注时, 会在添加脚注引用的位置出现带有链接的上标编号. 读者可以单击链接以跳至页面底部的脚注内容. 要创建脚注引用, 请在方括号中添加插入符号和标识符 ([^1]). 标识符可以是数字或单词, 但不能包含空格或制表符. 标识符仅将脚注引用与脚注本身相关联 - 在脚注输出中, 脚注按顺序编号. 在中括号内使用插入符号和数字以及用冒号和文本来添加脚注内容 ([^1]：这是一段脚注). 你不一定要在文档末尾添加脚注. 可以将它们放在除列表, 引用和表格等元素之外的任何位置. 这是一个数字脚注[^1]. 这是一个带标签的脚注[^label] [^1]: 这是一个数字脚注 [^label]: 这是一个带标签的脚注 这是一个数字脚注1. 这是一个带标签的脚注2 ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:12:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["网站使用笔记"],"content":"13 图片 图片的语法与链接相似, 但包含一个在前面的感叹号. ![Minion](https://octodex.github.com/images/minion.png) 或者: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The Stormtroopocat\r像链接一样, 图片也具有脚注样式的语法: ![Alt text][id] The Dojocat\r稍后在文档中提供参考内容, 用来定义 URL 的位置: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" 技巧\rLoveIt 主题提供了一个包含更多功能的 图片的 shortcode.\r这是一个数字脚注 ↩︎ 这是一个带标签的脚注 ↩︎ ","date":"2023-01-08","objectID":"/basic-markdown-syntax/:13:0","tags":["Markdown","网站使用笔记"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["papers"],"content":"2022年最新发表的NeuS变种：Geo-NeuS","date":"2023-01-04","objectID":"/geo-neus/","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":["papers"],"content":"公式推导 用有符号距离函数表示空间点p到物体表面的距离，sdf(p)等于0 使用两个神经网络估计SDF和颜色场 表示颜色场： 由于需要专注于表面的重建，所以将公式改写为 公式推导\r最后得到偏差的表达式： 网络的架构图，结合了三种loss，五个通道 架构图\r闭塞处理，这里没有看懂在干什么 SDF loss View-aware SDF loss. While rendering image $I_i$ from view $V_i$, we use the SDF network to estimate SDF values for the visible points $\\boldsymbol{P}_i$ of $V_i$. Based on the approximation that the SDF values of sparse points are zeroes, we propose the view-aware SDF loss: 值得注意的是，我们用来监督SDF网络的损失根据所呈现的视图而有所不同。这样，引入的SDF损失与显色渲染的过程是一致的。 这个loss应该向0收敛吗？是的 这里提到了他的模型使用了几何先验，是使用了什么作为先验？ 表达隐式平面，通过正负距离确定表面点。使用线性插值的方法求交点集。 多视角的几何约束： 使用MVS中的光学一致性来监督隐式表面的生成 MVS：MVS（Multi-View Stereo）的目的是在已知相机位姿的前提下估计稠密的三维结构，如果相机位姿未知则会先使用SfM得到相机的位姿。评估的稠密结构真值一般是基于Lidar（ETH3D[4]、Tanks and Temples[5]）或者深度相机（DTU[6]）获得整个场景的点云，而对应的相机位姿有的在采集的时候就通过机械臂直接获取[6]，有的则基于采集的深度进行估计[4][5]。 有了场景点云之后，一般评估指标为精度和完整度，同时还有二者的平衡指标F1分数。 精度（Accuracy）：对于每个估计出来的3D点寻找在一定阈值内的真值3D点，最终可以匹配上的比例即为精度。需要注意的是，由于点云真值本身不完整，需要先估计出真值空间中不可观测的部分，估计精度时忽略掉。 完整度（Completeness）：将每个真值的3D点寻找在一定阈值内最近的估计出来的3D点，最终可以匹配上的比例即为完整度。 F1分数（F1 Score）：精度和完整度是一对trade-off的指标，因为可以让点布满整个空间来让完整度达到100%，也可以只保留非常少的绝对精确的点来得到很高的精度指标。因此最终评估的指标需要对二者进行融合。假设精度为p，完整度为r，则F1分数为它们的调和平均数，即2pr / (p + r)。 然后得出几何一致损失 总体的损失函数： ","date":"2023-01-04","objectID":"/geo-neus/:1:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":["papers"],"content":"代码复现 GitHub网址：点击跳转 conda activate报错 CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'. 解决方案： source activate # 执行后命令行出现base标识 conda activate ... conda activate pytorch 报错 Could not find conda environment: pytorch You can list all discoverable environments with `conda info --envs`. conda install pytorch Executing transaction: failed ERROR conda.core.link:_execute(502): An error occurred while installing package 'conda-forge::certifi-2022.9.24-pyhd8ed1ab_0'. FileNotFoundError(2, \"No such file or directory: '/home/hanqi/.conda/envs/geoneus/bin/python3.7'\") Attempting to roll back. Rolling back transaction: done FileNotFoundError(2, \"No such file or directory: '/home/hanqi/.conda/envs/geoneus/bin/python3.7'\") 默认的安装路径是错的，我把forge卸载了，之后可以正常安装 anaconda search -t conda fvcore anaconda show ... 不知道为什么，anaconda3文件夹设置的是read only，如果要进行更新操作必须切换root用户 sudo s # 切换root用户 exit # 退出回到原来的用户 程序运行一段时间被kill了，定位发现是在这句话的时候 self.images_gray = torch.from_numpy(self.images_gray_np.astype(np.float32)).cuda() .cuda()是把数据储存到显卡里，可能是数据量太大了，我删除了一些照片，还剩十几张 训练过程中报错缺失npy文件 FileNotFoundError: [Errno 2] No such file or directory: 'pikachu_aruco/sfm_pts/points.npy' 查找后发现是作者没有给出这个文件的计算方法，只是说要modify 这个文件 运行指令需要两个，一个是数据文件夹，一个是保存的路径，直接运行报下面的错误 FileNotFoundError: [Errno 2] No such file or directory: 'pikachu_aruco/sparse/cameras.txt' 这个文件作者没有提供，也没有解释文件的内容是什么 对loss function具体内容的再阐述 整个网络的输入是稀疏点和多视角照片（可以参考网络架构图） def forward(self, inputs): \"\"\" :type input_rgb: object \"\"\" inputs = inputs * self.scale if self.embed_fn_fine is not None: inputs = self.embed_fn_fine(inputs) x = inputs for l in range(0, self.num_layers - 1): lin = getattr(self, \"lin\" + str(l)) if l in self.skip_in: x = torch.cat([x, inputs], 1) / np.sqrt(2) x = lin(x) if l \u003c self.num_layers - 2: x = self.activation(x) sdf网络中的forward函数其实返回的就是点的sdf值，对应文章中所说的MLP 监督过程发生在渲染的同时，渲染的同时我们会返回一个点的sdf值，那么我们已有的三维稀疏点也可以进行渲染，利用sdf网络来返回sdf值，因为我们假设三维稀疏点在表面，因此我们试着用网络来返回，如果网络准确，它应该返回一个接近于0的值，同时为了弥补三维稀疏点的缺陷，也进行一个视角射线的抽样，利用多视角的照片，进行操作抽取点，这些是中间的过程，就是所谓的隐式曲面的抽取。同样为了监督隐式曲面的抽取，光度一致性损失被提出，这些都是中途的过程。综合来说，输入只有三位稀疏点和各个角度的照片。 # Loss color_error = (color_fine - true_rgb) * mask color_fine_loss = F.l1_loss(color_error, torch.zeros_like(color_error), reduction='sum') / mask_sum psnr = 20.0 * torch.log10(1.0 / (((color_fine - true_rgb)**2 * mask).sum() / (mask_sum * 3.0)).sqrt()) eikonal_loss = gradient_error mask_loss = F.binary_cross_entropy(weight_sum.clip(1e-3, 1.0 - 1e-3), mask) sdf_loss = F.l1_loss(pts2sdf, torch.zeros_like(pts2sdf), reduction='sum') / pts2sdf.shape[0] ncc_loss = 0.5 * (ncc_cost.sum(dim=0) / (inside_sphere.sum(dim=0) + 1e-8)).squeeze(-1) loss = color_fine_loss + eikonal_loss * self.igr_weight + mask_loss * self.mask_weight + sdf_loss + ncc_loss 以上是loss的具体计算过程 renderer.py 代码解读 由于render内容很多，我会在另一篇文章中单独介绍这个文件的内容，点击此处跳转 ","date":"2023-01-04","objectID":"/geo-neus/:2:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":null,"content":"关于我","date":"2023-01-05","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":" 👋 Hi! I am Hanqi Jiang from Beijing Jiaotong University 👀 My Research Directions: Computer vision, deep learning, 3D reconstruction 📫 Contact me at: 20722010@bjtu.edu.cn or jhqyyds@gmail.com ","date":"2023-01-05","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Scientific research experience 2022.1 - 2022.3 CV algorithm intern at Baidu Online Network Technology (Beijing) Co., LTD., Xiaodu Cloud Platform Department, DuerOS algorithm team. 2022.4 - 2022.8 Algorithm engineer at China Telecom Co., Ltd. Beijing Research Institute China Telecom. 2022.4 - 2022.10 Algorithm engineer at Intelligent Computer Research Center, Institute of Computing Technology, Chinese Academy of Sciences. 2022.10 - 2023.4 Algorithm intern at Tsinghua University, autonomous driving lab. ","date":"2023-01-05","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Published paper Yuan, X., Jiang, H., \u0026 Zeng, L. (2023). Study on the process of preparing C4 olefin by catalytic coupling of ethanol. In Energy Revolution and Chemical Research (pp. 595-602). CRC Press. Available at: click here Yuan, X., Jiang, H., \u0026 Huang, L. (2022, August). DRL-Based Quantitative Algorithms for Gold and Bitcoin Portfolio Decisions. In 2022 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA) (pp. 878-881). IEEE. Available at: click here Liu, Z., Jiang, H., \u0026 Wang, T. (2022, October). Design and implementation of a quantitative investment system based on deep learning and data mining. In 2022 IEEE 2nd International Conference on Data Science and Computer Application (ICDSCA) (pp. 162-166). IEEE. Available at: click here ","date":"2023-01-05","objectID":"/about/:2:0","tags":null,"title":"关于我","uri":"/about/"}]