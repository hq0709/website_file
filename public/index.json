[{"categories":["papers"],"content":"2022å¹´æœ€æ–°å‘è¡¨çš„NeuSå˜ç§ï¼šGeo-NeuS","date":"0001-01-01","objectID":"/geo-neus/","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":["papers"],"content":"å…¬å¼æ¨å¯¼ ç”¨æœ‰ç¬¦å·è·ç¦»å‡½æ•°è¡¨ç¤ºç©ºé—´ç‚¹påˆ°ç‰©ä½“è¡¨é¢çš„è·ç¦»ï¼Œsdf(p)ç­‰äº0 $$\\partial \\Omega={\\boldsymbol{p} \\mid s d f(\\boldsymbol{p})=0}$$ ä½¿ç”¨ä¸¤ä¸ªç¥ç»ç½‘ç»œä¼°è®¡SDFå’Œé¢œè‰²åœº $$s \\hat{d} f(\\boldsymbol{p})=F_{\\Theta}(\\boldsymbol{p})$$ $$\\hat{c}(\\boldsymbol{o}, \\boldsymbol{v}, t)=G_{\\Phi}(\\boldsymbol{o}, \\boldsymbol{v}, t)$$ è¡¨ç¤ºé¢œè‰²åœºï¼š $$ C=\\hat{C}=\\sum_{i=1}^n w\\left(t_i\\right) \\hat{c}\\left(t_i\\right) $$ ç”±äºéœ€è¦ä¸“æ³¨äºè¡¨é¢çš„é‡å»ºï¼Œæ‰€ä»¥å°†å…¬å¼æ”¹å†™ä¸º $$ \\begin{aligned} C \u0026 =\\sum_{i=1}^{j-1} w\\left(t_i\\right) \\hat{c}\\left(t_i\\right)+w\\left(t_j\\right) \\hat{c}\\left(\\hat{t^}\\right)+w\\left(t_j\\right)\\left(\\hat{c}\\left(t_j\\right)-\\hat{c}\\left(\\hat{t^}\\right)\\right)+\\sum_{i=j+1}^n w\\left(t_i\\right) \\hat{c}\\left(t_i\\right) \\ \u0026 =w\\left(t_j\\right) \\hat{c}\\left(\\hat{t^}\\right)+\\varepsilon_{\\text {sample }}+\\sum_{\\substack{i=1 \\ i \\neq j}}^n w\\left(t_i\\right) \\hat{c}\\left(t_i\\right) \\ \u0026 =w\\left(t_j\\right) \\hat{c}\\left(\\hat{t^}\\right)+\\varepsilon_{\\text {sample }}+\\varepsilon_{\\text {weight }}, \\end{aligned} $$ å…¬å¼æ¨å¯¼\ræœ€åå¾—åˆ°åå·®çš„è¡¨è¾¾å¼ï¼š $$ \\Delta c=\\hat{c}\\left(\\hat{t}^\\right)-c\\left(t^\\right)=\\frac{\\left(1-w\\left(t_j\\right)\\right) c\\left(t^\\right)-\\varepsilon_{\\text {sample }}-\\varepsilon_{\\text {weight }}}{w\\left(t_j\\right)} $$ $$ \\delta c=\\frac{\\Delta c}{c\\left(t^\\right)}=\\frac{1}{w\\left(t_j\\right)}-1-\\frac{\\varepsilon_{\\text {sample }}+\\varepsilon_{\\text {weight }}}{w\\left(t_j\\right) c\\left(t^*\\right)} . $$ ç½‘ç»œçš„æ¶æ„å›¾ï¼Œç»“åˆäº†ä¸‰ç§lossï¼Œäº”ä¸ªé€šé“ æ¶æ„å›¾\ré—­å¡å¤„ç†ï¼Œè¿™é‡Œæ²¡æœ‰çœ‹æ‡‚åœ¨å¹²ä»€ä¹ˆ Occlusion handling. Because we focus on opaque objects, some parts of objects are invisible from view of a certain camera position. Therefore, there are only some of the sparse points visible for each view. For an image $I_i$ with camera position $\\boldsymbol{o}_i$, the visible points $\\boldsymbol{P}_i$ are consistent with feature points $\\boldsymbol{X}_i$ of $I_i$ $$ \\boldsymbol{X}_i=\\boldsymbol{K}_i\\left[\\boldsymbol{R}_i \\mid \\boldsymbol{t}_i\\right] \\boldsymbol{P}_i $$ where $\\boldsymbol{K}_i$ is the internal calibration matrix, $\\boldsymbol{R}_i$ is the rotation matrix and $\\boldsymbol{t}_i$ is the translation vector for image $I_i$. The coordinates of $\\boldsymbol{X}_i$ and $\\boldsymbol{P}_i$ are all homogeneous coordinates. The scale index before $\\boldsymbol{X}_i$ is omitted for simplicity. According to feature points of each image, we get visible points for each view and use them to supervise the SDF network while rendering image from the corresponding view. SDF loss View-aware SDF loss. While rendering image $I_i$ from view $V_i$, we use the SDF network to estimate SDF values for the visible points $\\boldsymbol{P}i$ of $V_i$. Based on the approximation that the SDF values of sparse points are zeroes, we propose the view-aware SDF loss: $$ \\mathcal{L}{S D F}=\\sum_{\\boldsymbol{p}_j \\in \\boldsymbol{P}_i} \\frac{1}{N_i}\\left|s \\hat{d} f\\left(\\boldsymbol{p}_j\\right)-s d f\\left(\\boldsymbol{p}j\\right)\\right|=\\sum{\\boldsymbol{p}_j \\in \\boldsymbol{P}_i} \\frac{1}{N_i}\\left|s \\hat{d} f\\left(\\boldsymbol{p}_j\\right)\\right|, $$ where $N_i$ is the number of points in $\\boldsymbol{P}_i$ and $|\\cdot|$ denotes the $L_1$ distance. It is worth noting that the loss we use to supervise the SDF network varies according to the view being rendered. In this way, the introduced SDF loss is consistent with the process of color rendering. å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ç”¨æ¥ç›‘ç£SDFç½‘ç»œçš„æŸå¤±æ ¹æ®æ‰€å‘ˆç°çš„è§†å›¾è€Œæœ‰æ‰€ä¸åŒã€‚è¿™æ ·ï¼Œå¼•å…¥çš„SDFæŸå¤±ä¸æ˜¾è‰²æ¸²æŸ“çš„è¿‡ç¨‹æ˜¯ä¸€è‡´çš„ã€‚ è¿™ä¸ªlossåº”è¯¥å‘0æ”¶æ•›å—ï¼Ÿæ˜¯çš„ è¿™é‡Œæåˆ°äº†ä»–çš„æ¨¡å‹ä½¿ç”¨äº†å‡ ä½•å…ˆéªŒï¼Œæ˜¯ä½¿ç”¨äº†ä»€ä¹ˆä½œä¸ºå…ˆéªŒï¼Ÿ è¡¨è¾¾éšå¼å¹³é¢ï¼Œé€šè¿‡æ­£è´Ÿè·ç¦»ç¡®å®šè¡¨é¢ç‚¹ã€‚ä½¿ç”¨çº¿æ€§æ’å€¼çš„æ–¹æ³•æ±‚äº¤ç‚¹é›†ã€‚ Occlusion-aware implicit surface capture. We use the implicit representation of the surface, and extract surface with the zero-level set of the implicit function. So the question is: Where is our implicit surface? According to Formula (3), the estimated surface is: $$ \\hat{\\partial \\Omega}={\\boldsymbol{p} \\mid s \\hat{d} f(\\boldsymbol{p})=0} . $$ We aim to optimize $\\hat{\\partial \\Omega}$ with geometry-consistent constraints among different views. Because the number of points on the surface is infinite, we need to sample points from $\\hat{\\partial \\Omega}$ in practice. To maintain consistency with the process of color rendering usin","date":"0001-01-01","objectID":"/geo-neus/:1:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":["papers"],"content":"ä»£ç å¤ç° conda activateæŠ¥é”™ CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'. è§£å†³æ–¹æ¡ˆï¼š source activate # æ‰§è¡Œåå‘½ä»¤è¡Œå‡ºç°baseæ ‡è¯† conda activate ... conda activate pytorch æŠ¥é”™ Could not find conda environment: pytorch You can list all discoverable environments with `conda info --envs`. conda install pytorch Executing transaction: failed ERROR conda.core.link:_execute(502): An error occurred while installing package 'conda-forge::certifi-2022.9.24-pyhd8ed1ab_0'. FileNotFoundError(2, \"No such file or directory: '/home/hanqi/.conda/envs/geoneus/bin/python3.7'\") Attempting to roll back. Rolling back transaction: done FileNotFoundError(2, \"No such file or directory: '/home/hanqi/.conda/envs/geoneus/bin/python3.7'\") é»˜è®¤çš„å®‰è£…è·¯å¾„æ˜¯é”™çš„ï¼Œæˆ‘æŠŠforgeå¸è½½äº†ï¼Œä¹‹åå¯ä»¥æ­£å¸¸å®‰è£… anaconda search -t conda fvcore anaconda show ... ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œanaconda3æ–‡ä»¶å¤¹è®¾ç½®çš„æ˜¯read onlyï¼Œå¦‚æœè¦è¿›è¡Œæ›´æ–°æ“ä½œå¿…é¡»åˆ‡æ¢rootç”¨æˆ· sudo s # åˆ‡æ¢rootç”¨æˆ· exit # é€€å‡ºå›åˆ°åŸæ¥çš„ç”¨æˆ· ç¨‹åºè¿è¡Œä¸€æ®µæ—¶é—´è¢«killäº†ï¼Œå®šä½å‘ç°æ˜¯åœ¨è¿™å¥è¯çš„æ—¶å€™ self.images_gray = torch.from_numpy(self.images_gray_np.astype(np.float32)).cuda() .cuda()æ˜¯æŠŠæ•°æ®å‚¨å­˜åˆ°æ˜¾å¡é‡Œï¼Œå¯èƒ½æ˜¯æ•°æ®é‡å¤ªå¤§äº†ï¼Œæˆ‘åˆ é™¤äº†ä¸€äº›ç…§ç‰‡ï¼Œè¿˜å‰©åå‡ å¼  è®­ç»ƒè¿‡ç¨‹ä¸­æŠ¥é”™ç¼ºå¤±npyæ–‡ä»¶ FileNotFoundError: [Errno 2] No such file or directory: 'pikachu_aruco/sfm_pts/points.npy' æŸ¥æ‰¾åå‘ç°æ˜¯ä½œè€…æ²¡æœ‰ç»™å‡ºè¿™ä¸ªæ–‡ä»¶çš„è®¡ç®—æ–¹æ³•ï¼Œåªæ˜¯è¯´è¦modify è¿™ä¸ªæ–‡ä»¶ è¿è¡ŒæŒ‡ä»¤éœ€è¦ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯æ•°æ®æ–‡ä»¶å¤¹ï¼Œä¸€ä¸ªæ˜¯ä¿å­˜çš„è·¯å¾„ï¼Œç›´æ¥è¿è¡ŒæŠ¥ä¸‹é¢çš„é”™è¯¯ FileNotFoundError: [Errno 2] No such file or directory: 'pikachu_aruco/sparse/cameras.txt' è¿™ä¸ªæ–‡ä»¶ä½œè€…æ²¡æœ‰æä¾›ï¼Œä¹Ÿæ²¡æœ‰è§£é‡Šæ–‡ä»¶çš„å†…å®¹æ˜¯ä»€ä¹ˆ fields.py åˆ†æˆå››ä¸ªclassï¼ŒSDF network, Rendering netwrk, SingleVariance network å’Œ NeRF ","date":"0001-01-01","objectID":"/geo-neus/:2:0","tags":["3D reconstruction","Deep learning"],"title":"Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction","uri":"/geo-neus/"},{"categories":null,"content":"å…³äºæˆ‘","date":"2023-01-05","objectID":"/about/","tags":null,"title":"å…³äºæˆ‘","uri":"/about/"},{"categories":null,"content":" ğŸ‘‹ Hi! I am Hanqi Jiang from Beijing Jiaotong University ğŸ‘€ My Research Directions: Computer vision, deep learning, 3D reconstruction ğŸ“« Contact me at: 20722010@bjtu.edu.cn or jhqyyds@gmail.com ","date":"2023-01-05","objectID":"/about/:0:0","tags":null,"title":"å…³äºæˆ‘","uri":"/about/"},{"categories":null,"content":"Scientific research experience 2022.1 - 2022.3 CV algorithm intern at Baidu Online Network Technology (Beijing) Co., LTD., Xiaodu Cloud Platform Department, DuerOS algorithm team. 2022.4 - 2022.8 Algorithm engineer at China Telecom Co., Ltd. Beijing Research Institute China Telecom. 2022.4 - 2022.10 Algorithm engineer at Intelligent Computer Research Center, Institute of Computing Technology, Chinese Academy of Sciences. 2022.10 - 2023.4 Algorithm intern at Tsinghua University, autonomous driving lab. ","date":"2023-01-05","objectID":"/about/:1:0","tags":null,"title":"å…³äºæˆ‘","uri":"/about/"},{"categories":null,"content":"Published paper Yuan, X., Jiang, H., \u0026 Zeng, L. (2023). Study on the process of preparing C4 olefin by catalytic coupling of ethanol. In Energy Revolution and Chemical Research (pp. 595-602). CRC Press. Available at: click here Yuan, X., Jiang, H., \u0026 Huang, L. (2022, August). DRL-Based Quantitative Algorithms for Gold and Bitcoin Portfolio Decisions. In 2022 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA) (pp. 878-881). IEEE. Available at: click here Liu, Z., Jiang, H., \u0026 Wang, T. (2022, October). Design and implementation of a quantitative investment system based on deep learning and data mining. In 2022 IEEE 2nd International Conference on Data Science and Computer Application (ICDSCA) (pp. 162-166). IEEE. Available at: click here ","date":"2023-01-05","objectID":"/about/:2:0","tags":null,"title":"å…³äºæˆ‘","uri":"/about/"}]